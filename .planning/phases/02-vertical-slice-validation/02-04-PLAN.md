---
phase: 02-vertical-slice-validation
plan: 04
type: execute
wave: 2
depends_on: [02-01, 02-02]
files_modified:
  - app/services/classifier.py
  - app/schemas/classification.py
autonomous: true

must_haves:
  truths:
    - "Azure OpenAI classifies insurer status as Critical, Watch, Monitor, or Stable"
    - "Structured output uses Pydantic model for guaranteed schema conformance"
    - "Bullet-point summaries generated in Portuguese"
  artifacts:
    - path: "app/services/classifier.py"
      provides: "ClassificationService with Azure OpenAI integration"
      exports: ["ClassificationService"]
      min_lines: 80
    - path: "app/schemas/classification.py"
      provides: "Pydantic models for structured output parsing"
      exports: ["NewsClassification", "InsurerClassification"]
  key_links:
    - from: "app/services/classifier.py"
      to: "app/config.py"
      via: "get_settings() for Azure OpenAI credentials"
      pattern: "get_settings\\(\\)"
    - from: "app/services/classifier.py"
      to: "app/schemas/classification.py"
      via: "response_format=NewsClassification"
      pattern: "response_format.*=.*NewsClassification"
---

<objective>
Create Azure OpenAI classification service with Pydantic structured outputs.

Purpose: Enables AI-powered insurer status classification and news summarization using Azure OpenAI's structured output feature for reliable JSON responses.

Output: ClassificationService that classifies news and generates Portuguese summaries.
</objective>

<execution_context>
@C:\Users\taylo\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\taylo\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/02-vertical-slice-validation/02-RESEARCH.md

# Dependencies
@app/config.py
@app/schemas/news.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create classification Pydantic schemas</name>
  <files>app/schemas/classification.py</files>
  <action>
Create Pydantic models for Azure OpenAI structured output:

```python
# app/schemas/classification.py
"""
Pydantic models for Azure OpenAI structured output classification.

These models define the expected response format for the classification
service, ensuring consistent and validated JSON responses from the LLM.
"""
from pydantic import BaseModel, Field
from typing import Literal


class NewsClassification(BaseModel):
    """
    Classification result for a single news item.

    Used with Azure OpenAI structured outputs to guarantee
    schema conformance in the API response.
    """

    status: Literal["Critical", "Watch", "Monitor", "Stable"] = Field(
        description="Insurer status based on news content impact"
    )
    summary_bullets: list[str] = Field(
        description="3-5 bullet points summarizing the news impact in Portuguese",
        min_length=1,
        max_length=5,
    )
    sentiment: Literal["positive", "negative", "neutral"] = Field(
        description="Overall sentiment of the news"
    )
    reasoning: str = Field(
        description="Brief explanation (1-2 sentences) of why this status was assigned"
    )


class InsurerClassification(BaseModel):
    """
    Aggregated classification for an insurer based on all their news.

    Used when classifying multiple news items together to determine
    overall insurer status.
    """

    overall_status: Literal["Critical", "Watch", "Monitor", "Stable"] = Field(
        description="Overall insurer status based on all news items"
    )
    key_findings: list[str] = Field(
        description="Top 3-5 key findings across all news in Portuguese",
        min_length=1,
        max_length=5,
    )
    risk_factors: list[str] = Field(
        description="Identified risk factors (may be empty for Stable)",
        default_factory=list,
    )
    sentiment_breakdown: dict[str, int] = Field(
        description="Count of positive, negative, neutral items",
        default_factory=lambda: {"positive": 0, "negative": 0, "neutral": 0},
    )
    reasoning: str = Field(
        description="Explanation of overall status determination in Portuguese"
    )
```
  </action>
  <verify>python -c "from app.schemas.classification import NewsClassification, InsurerClassification; print('Classification schemas OK')"</verify>
  <done>Pydantic models created for structured output parsing with proper field descriptions</done>
</task>

<task type="auto">
  <name>Task 2: Create ClassificationService with Azure OpenAI</name>
  <files>app/services/classifier.py</files>
  <action>
Create classification service based on research pattern:

```python
# app/services/classifier.py
"""
Azure OpenAI classification service for insurer news analysis.

Uses structured outputs with Pydantic models to ensure consistent
classification responses. All summaries generated in Portuguese.
"""
import logging
from typing import Any

from openai import AzureOpenAI

from app.config import get_settings
from app.schemas.classification import NewsClassification, InsurerClassification

logger = logging.getLogger(__name__)


# System prompts in Portuguese for better output consistency
SYSTEM_PROMPT_SINGLE = """Você é um analista financeiro especializado em seguradoras brasileiras.
Analise a notícia fornecida e classifique o status da seguradora.

Critérios de classificação:
- CRITICAL: Crise financeira, intervenção da ANS, risco de falência, fraude, acusações criminais
- WATCH: Atividade de M&A, mudanças significativas na liderança, ações regulatórias, perdas significativas
- MONITOR: Mudanças de tarifa, alterações na rede, expansão de mercado, anúncios de parcerias
- STABLE: Sem notícias significativas ou apenas atualizações operacionais rotineiras

Responda em português brasileiro para todos os campos de texto."""

SYSTEM_PROMPT_AGGREGATE = """Você é um analista financeiro especializado em seguradoras brasileiras.
Analise todas as notícias fornecidas sobre esta seguradora e determine o status geral.

Critérios de classificação:
- CRITICAL: Qualquer indicação de crise financeira, intervenção regulatória, ou risco sistêmico
- WATCH: M&A ativa, mudanças de liderança, ou ações regulatórias em andamento
- MONITOR: Mudanças comerciais normais, expansão, ou parcerias
- STABLE: Operações normais sem eventos significativos

Priorize o status mais grave se houver múltiplas indicações.
Responda em português brasileiro para todos os campos de texto."""


class ClassificationService:
    """
    Service for classifying insurer news using Azure OpenAI.

    Uses structured outputs with Pydantic models to ensure
    consistent and validated JSON responses from the LLM.
    """

    def __init__(self):
        settings = get_settings()

        if not settings.is_azure_openai_configured():
            logger.warning("Azure OpenAI not configured - classification will fail")
            self.client = None
            self.model = None
        else:
            self.client = AzureOpenAI(
                azure_endpoint=settings.azure_openai_endpoint,
                api_key=settings.azure_openai_api_key,
                api_version=settings.azure_openai_api_version,
            )
            self.model = settings.azure_openai_deployment

        self.use_llm = settings.use_llm_summary

    def classify_single_news(
        self,
        insurer_name: str,
        news_title: str,
        news_description: str | None = None,
    ) -> NewsClassification | None:
        """
        Classify a single news item for an insurer.

        Args:
            insurer_name: Name of the insurer
            news_title: News headline
            news_description: Optional news description/snippet

        Returns:
            NewsClassification object or None if classification fails
        """
        if not self.client or not self.use_llm:
            logger.info("LLM classification disabled or not configured")
            return self._fallback_classification()

        content = f"Título: {news_title}"
        if news_description:
            content += f"\n\nDescrição: {news_description}"

        user_prompt = f"""Analise esta notícia sobre {insurer_name}:

{content}

Forneça a classificação com resumo em bullet points."""

        try:
            completion = self.client.beta.chat.completions.parse(
                model=self.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_SINGLE},
                    {"role": "user", "content": user_prompt},
                ],
                response_format=NewsClassification,
                temperature=0,  # Deterministic outputs
            )

            return completion.choices[0].message.parsed

        except Exception as e:
            logger.error(f"Classification failed for {insurer_name}: {e}")
            return self._fallback_classification()

    def classify_insurer_news(
        self,
        insurer_name: str,
        news_items: list[dict[str, Any]],
    ) -> InsurerClassification | None:
        """
        Classify an insurer based on multiple news items.

        Aggregates all news to determine overall status and key findings.

        Args:
            insurer_name: Name of the insurer
            news_items: List of news items with title and description keys

        Returns:
            InsurerClassification object or None if classification fails
        """
        if not self.client or not self.use_llm:
            logger.info("LLM classification disabled or not configured")
            return self._fallback_insurer_classification()

        if not news_items:
            return self._fallback_insurer_classification()

        # Format news for prompt
        news_text = "\n\n".join([
            f"- {item.get('title', 'Sem título')}: {item.get('description', '')}"
            for item in news_items[:10]  # Limit to 10 items to avoid token limits
        ])

        user_prompt = f"""Analise estas {len(news_items)} notícias sobre {insurer_name}:

{news_text}

Determine o status geral da seguradora e forneça os principais achados."""

        try:
            completion = self.client.beta.chat.completions.parse(
                model=self.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_AGGREGATE},
                    {"role": "user", "content": user_prompt},
                ],
                response_format=InsurerClassification,
                temperature=0,
            )

            return completion.choices[0].message.parsed

        except Exception as e:
            logger.error(f"Aggregate classification failed for {insurer_name}: {e}")
            return self._fallback_insurer_classification()

    def _fallback_classification(self) -> NewsClassification:
        """Return fallback classification when LLM is unavailable."""
        return NewsClassification(
            status="Monitor",
            summary_bullets=["Classificação automática indisponível"],
            sentiment="neutral",
            reasoning="Classificação de fallback - LLM não configurado ou desabilitado",
        )

    def _fallback_insurer_classification(self) -> InsurerClassification:
        """Return fallback insurer classification when LLM is unavailable."""
        return InsurerClassification(
            overall_status="Monitor",
            key_findings=["Classificação automática indisponível"],
            risk_factors=[],
            sentiment_breakdown={"positive": 0, "negative": 0, "neutral": 0},
            reasoning="Classificação de fallback - LLM não configurado ou desabilitado",
        )

    def health_check(self) -> dict[str, Any]:
        """
        Check Azure OpenAI service connectivity.

        Returns dict with status and any error message.
        """
        if not self.client:
            return {"status": "error", "message": "Azure OpenAI not configured"}

        if not self.use_llm:
            return {"status": "disabled", "message": "LLM summarization disabled"}

        try:
            # Simple test completion
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "ping"}],
                max_tokens=5,
            )
            return {
                "status": "ok",
                "model": self.model,
            }
        except Exception as e:
            return {"status": "error", "message": str(e)}
```
  </action>
  <verify>python -c "from app.services.classifier import ClassificationService; s = ClassificationService(); print(s.health_check())"</verify>
  <done>ClassificationService created with classify_single_news, classify_insurer_news, and fallback handling</done>
</task>

<task type="auto">
  <name>Task 3: Update services __init__.py</name>
  <files>app/services/__init__.py</files>
  <action>
Export the classifier service:

```python
# app/services/__init__.py
from app.services.excel_service import parse_excel_upload, generate_excel_export
from app.services.scraper import ApifyScraperService
from app.services.classifier import ClassificationService
```
  </action>
  <verify>python -c "from app.services import ClassificationService; print('Export OK')"</verify>
  <done>ClassificationService exported from services package</done>
</task>

</tasks>

<verification>
1. Schemas import: `python -c "from app.schemas.classification import NewsClassification, InsurerClassification"`
2. Service imports: `python -c "from app.services.classifier import ClassificationService"`
3. Fallback works: Without config, service returns fallback classification
4. Health check: Returns appropriate status based on configuration
</verification>

<success_criteria>
- NewsClassification schema has status, summary_bullets, sentiment, reasoning fields
- InsurerClassification schema has overall_status, key_findings, risk_factors, sentiment_breakdown, reasoning
- ClassificationService uses AzureOpenAI client with structured outputs
- Prompts request Portuguese output explicitly
- Fallback classification returned when LLM unavailable or fails
- temperature=0 for deterministic outputs
- health_check() returns service status
</success_criteria>

<output>
After completion, create `.planning/phases/02-vertical-slice-validation/02-04-SUMMARY.md`
</output>
