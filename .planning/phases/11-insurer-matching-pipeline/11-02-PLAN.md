---
phase: 11-insurer-matching-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - app/services/ai_matcher.py
autonomous: true

must_haves:
  truths:
    - "Ambiguous articles (0 deterministic matches or >3) are sent to Azure OpenAI for insurer identification"
    - "The AI receives a list of insurer names/IDs with search_terms as context and returns structured InsurerMatchResult"
    - "When Azure OpenAI is unconfigured or fails, the matcher returns an unmatched result — never crashes the pipeline"
    - "Each AI match call is logged as an ApiEvent for cost monitoring"
  artifacts:
    - path: "app/services/ai_matcher.py"
      provides: "AIInsurerMatcher class with ai_match method"
      min_lines: 80
  key_links:
    - from: "app/services/ai_matcher.py"
      to: "app/services/classifier.py"
      via: "follows same Azure OpenAI client.beta.chat.completions.parse pattern"
      pattern: "client\\.beta\\.chat\\.completions\\.parse"
    - from: "app/services/ai_matcher.py"
      to: "app/models/api_event.py"
      via: "logs AI match events for cost tracking"
      pattern: "ApiEvent"
---

<objective>
Create the AI-assisted insurer matching service for ambiguous articles.

Purpose: When deterministic matching (Plan 01) cannot resolve an article to specific insurers (0 matches or too many matches), the AI matcher uses Azure OpenAI structured output to identify which of the 897 tracked insurers are mentioned. This handles ~20% of articles and is critical for complete coverage.

Output: `app/services/ai_matcher.py` with AIInsurerMatcher class.
</objective>

<execution_context>
@C:\Users\taylo\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\taylo\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-insurer-matching-pipeline/11-RESEARCH.md
@app/services/classifier.py
@app/schemas/classification.py
@app/config.py
@app/models/api_event.py
@app/models/insurer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AIInsurerMatcher service</name>
  <files>app/services/ai_matcher.py</files>
  <action>
Create `app/services/ai_matcher.py` with class `AIInsurerMatcher`.

**Follow the exact Azure OpenAI client initialization pattern from `app/services/classifier.py`** — including the corporate proxy URL detection logic. This is critical because BrasilIntel uses a corporate proxy endpoint format (`/deployments/{model}/chat/completions`).

**Internal Pydantic model for structured output:**
```python
class InsurerMatchResponse(BaseModel):
    """Structured output from Azure OpenAI for insurer matching."""
    insurer_ids: list[int] = Field(
        description="IDs of insurers mentioned in the article from the provided list. Empty if none.",
        default_factory=list
    )
    confidence: float = Field(
        description="Confidence 0-1 that the identification is correct",
        ge=0.0, le=1.0
    )
    reasoning: str = Field(
        description="Brief explanation of which insurer(s) were identified and why"
    )
```

**System prompt (in Portuguese for consistency with classifier):**
```
Voce e um assistente de IA que identifica quais seguradoras brasileiras sao mencionadas em artigos de noticias.

Lista de seguradoras disponiveis:
{insurer_context}

Analise o artigo e identifique qual(is) seguradora(s) da lista acima sao mencionadas.
- Retorne os IDs da lista acima.
- Se nenhuma seguradora for claramente mencionada, retorne uma lista vazia.
- Se multiplas seguradoras forem mencionadas, retorne todos os IDs relevantes.
- Considere variacoes de nomes (com e sem acentos, abreviacoes, nomes comerciais).
```

**Constructor:**
- Copy the OpenAI client initialization pattern from ClassificationService exactly (proxy detection, AzureOpenAI vs OpenAI, model extraction)
- Initialize structlog logger
- Store reference to settings for config checks

**Method: ai_match(article: dict, insurers: list[Insurer]) -> MatchResult:**
1. If client is None (unconfigured), return MatchResult(insurer_ids=[], confidence=0.0, method="unmatched", reasoning="AI matching unavailable — Azure OpenAI not configured")
2. Build insurer context string: `"ID {ins.id}: {ins.name} (termos: {ins.search_terms or 'nenhum'})"` for each insurer
   - IMPORTANT: Limit to first 200 insurers in the context to stay within token limits. Sort insurers by `enabled=True` first, then alphabetically. Log warning if truncated.
   - The 200 limit is configurable via a class constant `MAX_INSURER_CONTEXT = 200`
3. Build user prompt: article title + first 500 chars of description
4. Call `self.client.beta.chat.completions.parse(model=self.model, messages=[...], response_format=InsurerMatchResponse, temperature=0)`
5. Extract parsed result
6. Validate insurer_ids — filter out any IDs not in the provided insurer list (AI hallucination guard)
7. Record ApiEvent (use same _record_event pattern as FactivaCollector — own DB session, swallow errors):
   - event_type=ApiEventType.NEWS_FETCH (reuse existing type — the api_events table is generic)
   - api_name="ai_matcher"
   - success=True/False
   - detail=JSON with article_title (first 100 chars), matched_ids, confidence
8. Return MatchResult with method="ai_disambiguation"

**Error handling:**
- Wrap the entire OpenAI call in try/except
- On any exception: log warning with structlog, record failed ApiEvent, return MatchResult(insurer_ids=[], confidence=0.0, method="unmatched", reasoning=f"AI match failed: {error}")
- Use tenacity retry (2 attempts, exponential backoff) on the OpenAI call — same pattern as FactivaCollector

**Method: is_configured() -> bool:**
- Return `self.client is not None`

Import MatchResult from `app.schemas.matching` — this file is created in Plan 01, but since both plans are Wave 1, use a try/except import with a fallback comment explaining the dependency. The executor will run these plans in order (01 before 02) since they share no files, but the import must work.

Actually — since MatchResult is in a separate file that Plan 01 creates, and Plan 01 is in the same wave, the executor runs plans sequentially within a wave by plan number. So `app/schemas/matching.py` WILL exist when this plan runs. Import normally:
```python
from app.schemas.matching import MatchResult
```
  </action>
  <verify>
Run:
```
python -c "
from app.services.ai_matcher import AIInsurerMatcher
matcher = AIInsurerMatcher()
# Should initialize without error even if Azure OpenAI is not configured
print(f'AI matcher configured: {matcher.is_configured()}')
print('AIInsurerMatcher import and init successful')
"
```
This should print `AI matcher configured: False` (since Azure OpenAI creds are likely not in .env) and not crash.
  </verify>
  <done>AIInsurerMatcher class exists with ai_match method that uses Azure OpenAI structured output for insurer identification, validates returned IDs, logs ApiEvents, and gracefully degrades when unconfigured.</done>
</task>

</tasks>

<verification>
- `python -c "from app.services.ai_matcher import AIInsurerMatcher"` succeeds
- AIInsurerMatcher initializes without crashing when Azure OpenAI is not configured
- `is_configured()` returns False when credentials are missing
- The ai_match method returns MatchResult (not a custom type)
- ApiEvent recording follows same isolated-session pattern as FactivaCollector
</verification>

<success_criteria>
- AIInsurerMatcher follows the identical Azure OpenAI client init pattern as ClassificationService (including proxy detection)
- Structured output uses Pydantic model parsed via client.beta.chat.completions.parse
- Insurer context is limited to 200 entries with truncation logging
- All AI failures result in "unmatched" MatchResult, never exceptions
- ApiEvent records each AI match attempt with article context and result
</success_criteria>

<output>
After completion, create `.planning/phases/11-insurer-matching-pipeline/11-02-SUMMARY.md`
</output>
